# Investment Thesis: Due Diligence Arbiter

**The Fundable Pitch for Adversarial Multi-Model Research**

---

## The Verdict

| Dimension | Assessment |
|-----------|------------|
| **Productizability** | High — technology is ready, architecture is proven |
| **Fundability** | Very High (Seed/Series A) — VCs actively funding "Deep Research" |
| **Risk** | Medium — OpenAI feature risk if positioned as "general research" |

---

## Why This Is Fundable

### 1. The Problem Is Massive and Quantified

| Metric | Value |
|--------|-------|
| Global AI hallucination cost (2024) | $67.4 billion |
| Users experiencing hallucinations | 86% |
| Legal sanctions documented | 712+ cases |
| Professional verification tax | 20-39% of work time |

This isn't theoretical pain. It's costing real money, destroying real careers, and creating real lawsuits.

### 2. The Solution Is Technically Differentiated

**The Moat Argument:**

> "GPT-4o is smart but sycophantic. It agrees with the user.
>
> We built a Dissensus Engine. We force models to disagree, cluster the semantic entropy, and only report facts that survive the cross-fire.
>
> Our proprietary value isn't the LLM — it's the Disagreement Graph and the Arbiter Logic that we've tuned for investment due diligence."

**What Makes This Different:**
- Not a wrapper — genuine multi-model orchestration
- Disagreement as signal, not noise
- Calibrated uncertainty (semantic entropy)
- Domain-specific synthesis

### 3. The Timing Is Perfect

| Signal | Evidence |
|--------|----------|
| AI hallucination awareness | Peak mainstream attention |
| Regulatory pressure | EU AI Act, SEC guidance on AI disclosure |
| Enterprise AI adoption | Plateau due to trust issues |
| Research tool valuations | AlphaSense $4B, Perplexity $9B |

VCs are actively looking for the "trust layer" for AI. This is it.

### 4. The Market Is Proven

| Comparable | Valuation/ARR | What They Prove |
|------------|---------------|-----------------|
| AlphaSense | $4B valuation, $200M+ ARR | Research tools at enterprise scale |
| Perplexity | $9B valuation | AI search is massive |
| Consensus.app | $14.75M raised, ~$2M ARR | Scientific research synthesis |
| Patronus AI | $20M raised | Hallucination detection is fundable |

---

## The Trap to Avoid

**If you build a "General Research Assistant" (better Perplexity), you will die.**

OpenAI and Perplexity will add "Reasoning" and "Consensus" features natively within 6 months.

**The Winning Move:** Apply adversarial architecture to a vertical where accuracy is worth $100K+ and error is unacceptable.

---

## Why This Vertical (PE Due Diligence)

### The Wedge

| Attribute | PE Due Diligence |
|-----------|-----------------|
| Cost of being wrong | $1M+ (bad investment, LP trust) |
| Current verification spend | $20-50K per deal |
| Decision-maker accessibility | Search funds = direct access |
| Data availability | CIMs are shared documents |
| Sales cycle | 1-2 months (not 6-12) |

### The Beachhead

**Search Funds and Independent Sponsors**

| Why They're Perfect |
|---------------------|
| Personal capital at stake |
| Drowning in deal flow (50-100 to close 1) |
| Can't afford $50K diligence on every deal |
| Need to kill bad deals faster |
| Reachable on LinkedIn and Searchfunder.com |

### The Expansion Path

```
Search Funds ($1.5K/month)
    ↓
Independent Sponsors ($2.5K/month)
    ↓
Family Offices ($5K/month)
    ↓
Lower Middle Market PE ($10K/month)
    ↓
Enterprise PE/IB ($25K+/month)
```

---

## Competitive Positioning

### What Exists Today

| Product | What They Do | The Gap |
|---------|--------------|---------|
| AlphaSense | Search + snippets | No adversarial synthesis |
| Perplexity | AI search | No uncertainty quantification |
| Consensus | Paper agreement | Single model, no calibration |
| Patronus AI | Hallucination detection | Evaluates, doesn't generate |
| Expert Networks | Human experts | $700-1,350/hour, slow |

### What We Do Differently

| Capability | Us | Everyone Else |
|------------|-----|---------------|
| Multi-model adversarial | Yes | No |
| Uncertainty quantification | Yes | No |
| Disagreement visualization | Yes | No |
| Investment thesis stress-test | Yes | No |

### Defensibility

| Moat Layer | How It Compounds |
|------------|------------------|
| **Orchestration IP** | Multi-model routing, adversarial prompting |
| **Domain tuning** | Investment-specific claim extraction |
| **Data flywheel** | Every CIM analyzed improves disagreement detection |
| **Customer lock-in** | Custom prompts tuned to their criteria |
| **Relationship moat** | Direct founder relationships with searchers |

---

## Pitch Deck Narrative

### Slide 1: Problem

> "$67.4 billion was lost to AI hallucinations in 2024.
>
> 86% of professionals have been burned by confidently wrong AI.
>
> For investors, one wrong fact can mean a bad deal, damaged reputation, or LP lawsuit."

### Slide 2: Current Solutions Fail

> "Existing AI research tools synthesize to consensus. They hide disagreement.
>
> But in investing, knowing where experts disagree is MORE valuable than where they agree."

### Slide 3: Our Solution

> "We built a Dissensus Engine.
>
> Three AI models independently analyze your CIM: one builds the bull case, one attacks it, one arbitrates.
>
> You see exactly where they agree, where they disagree, and what needs human verification — in 4 hours, not 4 weeks."

### Slide 4: How It Works

```
[Demo screenshot or video]

CIM Upload → Bull/Bear/Analyst Analysis → Disagreement Graph →
Thesis Confidence Score + Suggested Diligence Questions
```

### Slide 5: Why Now

> - AI hallucination awareness at peak
> - Enterprise AI adoption stalling on trust
> - Regulatory pressure increasing
> - Research tool valuations proving market

### Slide 6: Traction

> [After early customers]
> - X search funds paying $Y/month
> - Z% month-over-month growth
> - Avg customer saves A hours/deal
> - B referrals from existing customers

### Slide 7: Market

> - Expert network industry: $2.5B (9% YoY growth)
> - Research tools market: $15B+
> - PE/VC AUM: $13T+
> - Our SAM: $500M (search funds + family offices + LMM PE)

### Slide 8: Business Model

> | Tier | Price | Target |
> |------|-------|--------|
> | Search Fund | $1,500/month | Individual searchers |
> | Family Office | $5,000/month | Direct investment teams |
> | Enterprise | $15K+/month | PE firms |
>
> 95% gross margins. <3 month CAC payback.

### Slide 9: Competition

> | Them | Us |
> |------|-----|
> | Single model | Multi-model adversarial |
> | Hide disagreement | Surface disagreement |
> | General purpose | Investment-specific |
> | API costs = margin pressure | Premium pricing = healthy margins |

### Slide 10: Team

> [Your background]
> - 8+ years engineering
> - [Relevant domain experience]
> - Built the full technical architecture solo
> - [Any relevant PE/finance exposure]

### Slide 11: Ask

> Raising $X seed to:
> - Hire 2 engineers
> - Expand from search funds to family offices
> - Build enterprise features
> - 18-month runway to Series A metrics

---

## Metrics That Matter for Raise

### Minimum Viable Metrics (Pre-Seed)

| Metric | Target |
|--------|--------|
| Paying customers | 3+ |
| MRR | $4,500+ |
| Demo video | Compelling |
| Design partner feedback | Positive quotes |

### Seed Metrics

| Metric | Target |
|--------|--------|
| Paying customers | 10+ |
| MRR | $15,000+ |
| Growth rate | 30%+ MoM |
| Gross margin | 90%+ |
| NPS | 50+ |
| Churn | <10% monthly |

### Series A Metrics

| Metric | Target |
|--------|--------|
| ARR | $1M+ |
| Customers | 50+ |
| NDR | 120%+ |
| CAC payback | <6 months |
| Multi-segment | Search + FO + PE |

---

## Risk Factors (Honest Assessment)

### Technical Risks

| Risk | Mitigation |
|------|------------|
| Uncertainty calibration is unsolved research | Use semantic entropy (proven), not verbalized confidence |
| Multi-model costs are high | Aggressive caching, tiered complexity routing |
| Output quality varies by model | Continuous prompt engineering, model selection |

### Market Risks

| Risk | Mitigation |
|------|------------|
| OpenAI adds similar features | Vertical focus = they won't specialize here |
| Slow enterprise sales | Start with search funds (fast sales) |
| Churn in small customer base | Direct founder relationship, fast iteration |

### Execution Risks

| Risk | Mitigation |
|------|------------|
| Solo founder bandwidth | Focus ruthlessly on core product |
| No domain expertise | Partner with ex-PE for advisory |
| Sales-heavy GTM | Product-led growth after initial traction |

---

## Why Now Is the Right Time

### Market Timing

1. **AI hallucination awareness peaked** — everyone knows the problem
2. **Enterprise AI adoption stalling** — trust is the blocker
3. **Regulatory pressure increasing** — EU AI Act, SEC guidance
4. **Research tool exits proving market** — AlphaSense, Tegus

### Technical Timing

1. **Multi-model APIs mature** — GPT-4o, Claude 3.5, Gemini all production-ready
2. **LangGraph enables orchestration** — wasn't possible 18 months ago
3. **Semantic entropy methods proven** — Nature paper 2024
4. **Structured output reliable** — Instructor library mature

### Competitive Timing

1. **No one doing adversarial synthesis** — whitespace is real
2. **Incumbents focused elsewhere** — Perplexity on consumer, AlphaSense on search
3. **Patronus evaluates, doesn't generate** — different product
4. **Window before consolidation** — 12-18 months

---

## The Bottom Line

This is fundable because:

1. **The problem is quantified** ($67B+ annual losses)
2. **The solution is differentiated** (adversarial multi-model, not wrapper)
3. **The market is proven** (AlphaSense $4B, research tools growing)
4. **The timing is right** (trust crisis + technical maturity)
5. **The beachhead is accessible** (search funds, fast sales)
6. **The expansion path is clear** (FO → PE → IB)

**Risk:** If positioned as "general AI research," OpenAI wins.

**Win condition:** Own "adversarial investment research" before the big players notice.
